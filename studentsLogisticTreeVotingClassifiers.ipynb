{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# pibit empresa 'SELEÇÃO DE CARACTERÍSTICAS PARA PREVISÃO DO DESEMPENHO DE ALUNOS EM CURSOS DE EAD'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the data\n",
    "students_data = pd.read_csv('student-por.csv', sep=';', true_values=['yes'], false_values=['no'])\n",
    "students_data.sample(5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add boolean column PassFail\n",
    "def passfail(row):\n",
    "    if row['G3'] >= 10:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "students_data['PassFail'] = students_data.apply(lambda row: passfail(row), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# data visualisation\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "students_data.G3.hist(ax=axes[0])\n",
    "axes[0].set_title(\"Distribuição de G3\")\n",
    "sns.countplot(x=\"PassFail\", data=students_data, ax=axes[1])\n",
    "axes[1].set_title(\"Distribuição entre Aprovados/Reprovados\")\n",
    "plt.grid(True, axis='y')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separate target from predictors\n",
    "Y = students_data.PassFail\n",
    "X = students_data.drop(['absences', 'G1', 'G2', 'G3', 'PassFail'], axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def conf_matrix(prediction, Y_validation):\n",
    "    \"\"\" Confusion Matrix for dataset predictions\n",
    "    :type Y_validation: dataframe\n",
    "    :type prediction: dataframe\n",
    "    \"\"\"\n",
    "    y_valid = [i for i in Y_validation]\n",
    "    truepred = [0, 0]\n",
    "    falsepred = [0, 0]\n",
    "    for i in range(len(prediction)):\n",
    "        if prediction[i]:\n",
    "            if prediction[i] == y_valid[i]:\n",
    "                truepred[0] += 1\n",
    "            else:\n",
    "                truepred[1] += 1\n",
    "        else:\n",
    "            if prediction[i] != y_valid[i]:\n",
    "                falsepred[0] += 1\n",
    "            else:\n",
    "                falsepred[1] += 1\n",
    "    return pd.DataFrame(np.array([truepred, falsepred]), columns=['True', 'False'], index=['TruePred', 'FalsePred'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def scale_numeric(data, numeric_columns, scale):\n",
    "    for col in numeric_columns:\n",
    "        data[col] = scale.fit_transform(data[col].values.reshape(-1, 1))\n",
    "    return data\n",
    "\n",
    "\n",
    "# We can now define the scaler we want to use and apply it to our dataset\n",
    "scaler = StandardScaler()\n",
    "X = scale_numeric(X, [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']], scaler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# columns types\n",
    "students_num_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
    "students_cat_cols = [cname for cname in X.columns if X[cname].nunique() < 10 and\n",
    "                     X[cname].dtype == \"object\"]\n",
    "students_bool_cols = [cname for cname in X.columns if X[cname].dtype == \"bool\"]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = students_cat_cols + students_num_cols + students_bool_cols\n",
    "X = X[my_cols].copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Divide data into training and validation subsets\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, train_size=0.8, test_size=0.2, stratify=Y,\n",
    "                                                      shuffle=True)\n",
    "# Get shape of test and training sets\n",
    "print('Training Set:')\n",
    "print('Number of datapoints: ', X_train.shape[0])\n",
    "print('Number of features: ', X_train.shape[1])\n",
    "print('Test Set:')\n",
    "print('Number of datapoints: ', X_valid.shape[0])\n",
    "print('Number of features: ', X_valid.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant')),\n",
    "                                        ('filter', VarianceThreshold(threshold=0.01))])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, students_num_cols),\n",
    "        ('cat', categorical_transformer, students_cat_cols),\n",
    "        ('bool', 'passthrough', students_bool_cols)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Choose model\n",
    "model1 = DecisionTreeClassifier(criterion='entropy')\n",
    "model2 = RandomForestClassifier(n_estimators=100)\n",
    "model3 = LogisticRegression(solver='lbfgs')\n",
    "voting_clf = VotingClassifier(estimators=[('dt', model1), ('rf', model2), ('lr', model3)],\n",
    "                              # here we select soft voting, which returns the argmax of the sum of\n",
    "                              # predicted probabilities\n",
    "                              voting='soft', weights=[1, 1, 1])\n",
    "models = [model1, model2, model3, voting_clf]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "feature_selector = SequentialFeatureSelector(DecisionTreeClassifier(),\n",
    "                                             n_jobs=-1,\n",
    "                                             k_features=15,\n",
    "                                             forward=True,\n",
    "                                             verbose=2,\n",
    "                                             scoring='accuracy',\n",
    "                                             cv=0)\n",
    "print('Decision Tree Classifier')\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('features', feature_selector), ('model', models[0])])\n",
    "my_pipeline.fit(X_train, Y_train)\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix(preds, Y_valid))\n",
    "score = accuracy_score(Y_valid, preds)\n",
    "print(\"Accuracy score without xvalidation:\\n\", score)\n",
    "scores = cross_val_score(my_pipeline, X_train, Y_train, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy scores:\\n\", scores)\n",
    "mean = scores.mean()\n",
    "print(mean)\n",
    "print('End of model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "feature_selector = SequentialFeatureSelector(RandomForestClassifier(),\n",
    "                                             n_jobs=-1,\n",
    "                                             k_features=15,\n",
    "                                             forward=True,\n",
    "                                             verbose=2,\n",
    "                                             scoring='accuracy',\n",
    "                                             cv=0)\n",
    "print('Random Forest Classifier')\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),  ('model', models[1])])\n",
    "my_pipeline.fit(X_train, Y_train)\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix(preds, Y_valid))\n",
    "score = accuracy_score(Y_valid, preds)\n",
    "print(\"Accuracy score without xvalidation:\\n\", score)\n",
    "scores = cross_val_score(my_pipeline, X_train, Y_train, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy scores:\\n\", scores)\n",
    "mean = scores.mean()\n",
    "print(mean)\n",
    "print('End of model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "feature_selector = SequentialFeatureSelector(LogisticRegression(),\n",
    "                                             n_jobs=-1,\n",
    "                                             k_features=15,\n",
    "                                             forward=True,\n",
    "                                             verbose=2,\n",
    "                                             scoring='accuracy',\n",
    "                                             cv=0)\n",
    "print('Logistic Regression')\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('features', feature_selector), ('model', models[2])])\n",
    "my_pipeline.fit(X_train, Y_train)\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix(preds, Y_valid))\n",
    "score = accuracy_score(Y_valid, preds)\n",
    "print(\"Accuracy score without xvalidation:\\n\", score)\n",
    "scores = cross_val_score(my_pipeline, X_train, Y_train, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy scores:\\n\", scores)\n",
    "mean = scores.mean()\n",
    "print(mean)\n",
    "print('End of model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "feature_selector = SequentialFeatureSelector(VotingClassifier(estimators=[('dt', model1), ('rf', model2), ('lr', model3)]),\n",
    "                                             n_jobs=-1,\n",
    "                                             k_features=15,\n",
    "                                             forward=True,\n",
    "                                             verbose=2,\n",
    "                                             scoring='accuracy',\n",
    "                                             cv=0)\n",
    "print('Voting Classifier')\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('features', feature_selector), ('model', models[3])])\n",
    "my_pipeline.fit(X_train, Y_train)\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix(preds, Y_valid))\n",
    "score = accuracy_score(Y_valid, preds)\n",
    "print(\"Accuracy score without xvalidation:\\n\", score)\n",
    "scores = cross_val_score(my_pipeline, X_train, Y_train, cv=5, scoring='accuracy')\n",
    "print(\"Accuracy scores:\\n\", scores)\n",
    "mean = scores.mean()\n",
    "print(mean)\n",
    "print('End of model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}